==================[Syllabus Start]==================
Applied Machine Learning
2019 Fall CS5785 Cornell Tech
Fall 2019 is here! Here's what you need to know.
Course Description
Learn and apply key concepts of modeling, analysis and validation from Machine Learning, Data Mining and
Signal Processing to analyze and extract meaning from data. 
Implement algorithms and perform experiments
on images, text, audio and mobile sensor measurements. 
Gain working knowledge of supervised and
unsupervised techniques including classification, regression, clustering, feature selection, association rule
mining and dimensionality reduction.
Prerequisites
CS 2800 or equivalent, Linear Algebra, and experience programming with Python or Matlab, or permission of
the instructor.
Room & Time
Tuesdays and Thursdays, 12:30PM-1:45PM, Bloomberg Center 131, Cornell Tech
Class number: 12453
Links:
 
CMS
 (https://cms.csuglab.cornell.edu/web/auth/?action=loginview)
 for homework submission, 
Slack
(https://cs5785fall2019.slack.com/)
 for discussions. To join slack, please use this 
link
(https://join.slack.com/t/cs5785fall2019/shared_invite/enQtNzQwNTA4MTc5NDkyLWUyYzQ5NjRiNDM0YzJiY2U4YjdlNWEzMGZmYmY3YTgyZjVkMTExMzUwMTViMGYwMjQ2ZWJjMTEzMGQzNWUyY2I)
Textbooks (Available for free)
Required:
 
T. Hastie, R. Tibshirani and J. Friedman, 
The Elements of Statistical Learning: Data Mining, Inference, and
Prediction (2nd edition)
 (http://web.stanford.edu/~hastie/ElemStatLearn/)
, Springer-Verlag, 2008.
Recommended:
 
Yaser S. Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Lin: 
Learning from Data
(http://work.caltech.edu/textbook.html)
, AMLBook, 2012.
P. Harrington, 
Machine Learning in Action
 (http://www.manning.com/pharrington/)
, Manning, 2012.
A. Rajaraman, J. Leskovec and J. Ullman, 
Mining of Massive Datasets
(http://infolab.stanford.edu/~ullman/mmds.html)
, v1.1.
H. Daumé III, 
A Course in Machine Learning
 (http://ciml.info/)
, v0.8.
Course Requirements and Grading
Grade Breakdown:
 Your grade will be determined by the assignments (30%), one prelim (30%), a final
exam (30%), and in-class quizzes (10%).
Homework: 
There will be four assignments and an “assignment 0” for environment setup. Each
assignment will have a due date for completion. Half of the points of the lowest-scoring assignment will
count as extra credit, meaning the points received for homeworks 1, 2, 3, and 4 is calculated as (sum of
scores) / 3.5.
Late Policy: 
Each student has a total of 
one
 slip day that may be used without penalty.
External Code: 
Unless otherwise specified, you are allowed to use well known libraries such as 
scikit-
learn, scikit-image, numpy, scipy,
 etc. in the assignments. Any reference or copy of public code
repositories should be properly cited in your submission (examples include 
Github, Wikipedia, Blogs
).
In some assignment cases, you are NOT allowed to use any of the libraries above, please refer to
individual HW instructions for more details.
Collaboration: 
You are encouraged (but not required) to work in groups of no more than 2 students on
each assignment. Please indicate the name of your collaborator at the top of each assignment and cite any
references you used (including articles, books, code, websites, and personal communications). If you’re
not sure whether to cite a source, err on the side of caution and cite it. You may submit just one writeup
for the group. Remember not to plagiarize: all solutions must be written by members of the group.
Quizzes: 
There will be surprise in-class quizzes to make sure you attend and pay attention to the class.
Prelim: October 22 
in class. The exam is closed book but you are allowed to bring one sheet of written
notes (Letter size, two-sided). You are allowed to use a calculator. 
Past Prelim 0
 (prelims/prelim-0.pdf)
Past Prelim 1
 (prelims/prelim-1.pdf)
Past Prelim 2
 (prelims/prelim-2.pdf)
Final Exam: December 3-10.
 The final exam will be hosted on Kaggle. You will develop an algorithm,
prepare a professional paper, submit an anonymized version to the EasyChair conference system, and
peer-review the work from other groups. You are strongly encouraged to work in a group of three
students.
Copyright © Applied Machine Learning 2019

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
