==================[Syllabus Start]==================
CS	  57800	  –	  Statistical	  Machine	  Learning	  Time:	  MW	  5:30pm-­‐6:45pm	  Loca:on:	  Peirce	  Hall	  277	  Instructor:	  Elias	  Bareinboim	  Webpage:	  h>p://www.cs.purdue.edu/~eb/	  Summary	  	  This	  course	  is	  moFvated	  by	  the	  need	  for	  providing	  diﬀerent	  levels	  of	  “explanaFon”	  to	  the	  vast	  amount	  of	  data	  collected	  in	  diﬀerent	  ﬁelds	  of	  human	  inquiry,	  including	  	  engineering,	  medicine,	  and	  the	  empirical	  sciences.	  DeparFng	  from	  structural	  causal	  models,	  we	  will	  study	  the	  concepts,	  principles,	  and	  algorithms	  	  necessary	  to	  solve	  modern,	  large-­‐scale	  machine	  learning	  problems.	  We	  will	  study	  the	  tradeoﬀs	  involved	  in	  answering	  mulFple	  types	  of	  queries,	  including	  associaFonal,	  causal,	  and	  counterfactual.	  For	  instance,	  we	  will	  discuss	  under	  what	  condiFons	  non-­‐experimental	  data	  can	  be	  used	  to	  infer	  causal	  knowledge.	  	  Prerequisites	  In	  order	  to	  be	  successful	  in	  this	  course,	  you	  should	  have	  a	  basic	  knowledge	  of:	  -­‐Discrete	  Math	  (proof	  techniques,	  search	  algorithms,	  and	  graph	  theory)	  -­‐Calculus	  (ﬁnd	  min/max	  of	  funcFons)	  -­‐Linear	  Algebra	  (vectors	  and	  matrices)	  -­‐StaFsFcs	  (basic	  probability,	  modeling,	  experimental	  design)	  -­‐Some	  programming	  experience	  (with	  special	  understanding	  of	  complexity	  analysis)	  	  People	  If	  you	  have	  quesFons	  about	  lectures	  or	  material,	  please	  ask	  them	  on	  piazza,	  rather	  than	  emailing.	  Material	  (tenta:ve)	  	  The	  following	  is	  a	  rough	  outline	  of	  the	  material	  we	  will	  cover.	  Depending	  on	  how	  fast	  things	  go,	  we	  might	  switch	  some	  things	  around	  during	  the	  semester.	  NameEmailOﬃce	  HoursLoca:onElias	  Bareinboimeb@purdue.eduWed	  11:30-­‐12:30pmLWSN	  2142LDaniel	  Kumor	  (TA)dkumor@purdue.eduFri	  12-­‐1pmLWSN	  B116
WeekSubjectMaterialTextbook1IntroducFonMoFvaFon,	  3-­‐layer	  scienFﬁc	  hierarchy,	  	  review	  probability.	  2ProbabilisFc	  Graphical	  ModelsGraphoids,	  i-­‐maps,	  d-­‐separaFon,	  Bayesian	  Networks,	  Naive	  Bayes,	  Markov	  Random	  Fields,	  Hidden	  Markov	  Models,	  RelaFon	  Models,	  variable	  eliminaFon,	  belief	  propagaFon,	  sampling,	  parameter	  learning.ProbabilisFc	  Graphical	  Models:	  Principles	  and	  Techniques.	  Daphne	  Koller	  and	  Nir	  Friedman	  ISBN:	  86014011130343456Causal	  ModelsCausal	  Bayesian	  Networks,	  Structural	  Learning,	  do-­‐operator,	  confounding	  bias,	  Simpson’s	  paradox,	  Back-­‐door	  criterion,	  do-­‐calculus,	  sampling	  selecFon	  bias,	  transportability,	  structural	  causal	  models,	  counterfactual	  reasoning.	  Causality:	  Models,	  Reasoning	  and	  Inference.	  Judea	  Pearl	  ISBN:	  9780521895606789Midterm10Supervised	  	  	  	  	  	  	  LearningDecision	  Trees,	  Regression,	  SVM,	  VC	  dimension,	  Perceptron,	  Deep	  Learning,	  PAC	  learning.	  Pa>ern	  RecogniFon	  and	  Machine	  Learning,	  Christopher	  Bishop.	  	  ISBN:	  9780387310732	  Reinforcement	  Learning:	  An	  IntroducFon,	  Richard	  S.	  Su>on.	  ISBN:	  9780262193986	  1112Unsupervised	  LearningClustering,	  k-­‐means,	  hierarchical,	  expectaFon	  maximizaFon.	  1314Reinforcement	  LearningBandits,	  Markov	  Decision	  Process,	  Value	  FuncFon,	  Policy	  search.	  1516Final	  Exam
Grading	  -­‐Midterm	  exam:	  30%	  -­‐Final	  exam:	  40%	  -­‐Homeworks:	  30%	  oAbout	  5	  homework	  assignments	  -­‐A>endance	  and	  parFcipaFon:	  bonus	  Please	  review	  the	  Purdue	  honor	  code.	  While	  working	  on	  assignments	  in	  small	  teams	  is	  okay,	  your	  homework	  soluFons	  must	  be	  your	  own.	  Course	  Policies	  You	  are	  expected	  to	  a>end	  lectures	  and	  parFcipate	  in	  class.	  While	  taking	  notes	  on	  laptops	  and	  small	  snacks	  are	  allowed,	  please	  make	  sure	  you	  are	  quiet	  and	  respeclul	  of	  those	  around	  you,	  including	  those	  behind	  you	  who	  might	  be	  distracted	  by	  your	  snacks/devices.	  	  You	  are	  expected	  to	  come	  prepared	  to	  class,	  and	  to	  parFcipate	  in	  class	  discussion,	  especially	  when	  something	  is	  not	  clear.	  If	  you	  are	  too	  shy	  to	  ask	  in	  class,	  please	  post	  on	  piazza	  or	  a>end	  oﬃce	  hours.	  

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
