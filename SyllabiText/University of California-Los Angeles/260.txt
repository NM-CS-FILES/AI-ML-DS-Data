==================[Syllabus Start]==================
View on GitHub
CS260 [Fall2022] Machine Learning Algorithms
Overview
This course introduces the foundational concepts and algorithms of machine learning and deep learning. The goal of this course is to endow the
student with a) a solid understanding of the foundational concepts of machine learning, and b) morden machine learning techniques such as deep
learning. Topics to be covered include empirical risk minimization, PAC learning, Agnostic PAC learning, perceptron, linear regression, boosting,
stochastic gradient descent, support vector machines, multi-layer perceptron, convolutional neural networks, recurrent neural networks, attention
mechanism. Slides and homework assignments will be released on this website. Homework solutions will only be released on Bruinlearn.
Prerequisites
Calculus, linear algebra, probability and statistics, and Python programming.
Textbook
[SSBD] Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algorithms. Cambridge University
Press, 2014.
[ZLLS] Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola, Dive into Deep Learning.
Feifei Li, Jiajun Wu, Ruohan Gao, CS231n: Deep Learning for Computer Vision 
course website
Programming Language
Python, Pytorch
Logistics
Time: 
Monday and Wednesday 2:00PM - 3:50PM
Location: 
DODD 147
Instructor: 
Quanquan Gu
 (Email: qgu at cs dot ucla dot edu)
Teaching Assistant:
Zixiang Chen, Section 1A (Email: chenzx19 at cs dot ucla dot edu)
Jiafan He, Section 1B (Email: jiafanhe19 at g dot ucla dot edu)
Lucas Tecot, Section 1C (Email: lucastecot at gmail dot com)
Office hours:
The instructor’s office hour is Thursday 9:00am-10:00am, EVI 382.
The TA’s office hour is
Zixiang Chen, Monday 10am-12pm, Boelter 3256S-A
Jiafan He, Thursday 1-3pm, Boelter 3256S-F
Lucas Tecot, Wednesday 10am-12pm, Boelter 3256S-F
Course Website: 
https://uclaml.github.io/CS260-Fall2022/
Course Forum: 
https://piazza.com/ucla/fall2022/cs260/home
 (If you haven’t already, 
sign up here
.)
Grading Policy
Grades will be computed based on the following factors:
Homework 35%
Quiz 5%
Midterm 30%
Final Project 30%
Schedule
#
Date
Topics
Reading
Homework
1
9/26
Introduction (
slides
)
Chapter 1, 2.1 of [SSBD]
 
2
9/28
Empirical Risk Minimization, PAC Learning (
slides
)
Chapter 2 of [SSBD]
HW1 Out
 
Latex Template
 
9/30
TA Session Week 1 (
1A slides
)(
1B slides
)(
1C slides
)
 
 
3
10/3
Agnostic PAC Learning (
slides
)
Chapter 3, 4 of [SSBD]
 
3
10/3
Agnostic PAC Learning (
slides
)
Chapter 3, 4 of [SSBD]
 
4
10/5
Bias-Complexity Tradeoff (
slides
)
Chapter 5, 11 of [SSBD]
 
 
10/7
TA Session Week 2 (
1A slides
)(
1B slides
)(
1C slides
)
 
 
5
10/10
Perceptron/Linear regression (
slides
)
Chapter 9, 19 of [SSBD]
HW1 Due,
6
10/12
Boosting (
slides
)
Chapter 10 of [SSBD]
HW2 Out
 
10/14
TA Session Week 3(
1A slides
)(
1B slides
)(
1C slides
)
 
 
7
10/17
Boosting, Convex Learning and SGD (
slides
)
Chapter 12, 14 of [SSBD]
 
8
10/19
AI4Database
Guest lecture
 
 
10/21
TA Session Week 4 (
1A slides
)(
1B slides
)(
1C slides
)
 
HW2 Due,
9
10/24
Convex Learning and SGD (
slides
)
Chapter 12, 14 of [SSBD]
HW3 Out
10
10/26
Regularization and Stability, Support Vector Machines (
slides
)
Chapter 13 and 15 of [SSBD]
 
 
10/28
TA Session Week 5 (
1A slides
)(
1B slides
) (
1C slides
)
 
 
11
10/31
Kernel Methods (
slides
)
Chapter 16 of [SSBD]
 
12
11/2
Multi-layer Perceptron I (
slides
)
Chapter 4 and 5 of [ZLLS]
HW3 Due
 
11/4
TA Session Week 6(
1B slides
)
 
 
 
11/7
Midterm Exam
 
HW4 Out
13
11/9
Multi-layer Perceptron 
II (
slides
)
Chapter 4 and 5 of [ZLLS]
 
 
11/11
TA Session Week7
 
 
14
11/14
Covolutional Neural Networks I (
slides
)
Chapter 7 of [ZLLS]
 
15
11/16
Covolutional Neural Networks II (
slides
)
Chapter 8 of [ZLLS]
HW4 Due 
HW5 Out
 
11/18
TA Session Week 8 (
1B slides
)
 
 
16
11/21
Recurrent Neural Networks I (
slides
)
Chapter 9 of [ZLLS]
 
17
11/23
Recurrent Neural Networks II (
slides
)
Chapter 10 of [ZLLS]
HW5 Due, 
HW6 Out
 
11/28
Canceled Due to NeurIPS
 
 
18
11/30
Attention Mechanisms (
slides
）
Chapter 11 of [ZLLS]
 
 
12/2
TA Session Week10 
(
slides
）
 
 
 
12/7
 
 
HW6 Due
 
12/8
Final Project Presentation
 
 
 
12/11
 
 
Project Report/Slides Due
Academic Integrity Policy
Students are encouraged to read the 
UCLA Student Conduct Code
 for Academic Integrity.
Homework
There will be about 5 homework assignments during the semester as we cover the corresponding material. Homework consists of both
mathematical derivation, algorithm analysis and programming. Homework is required to be written in Latex. Latex homework template can be
found 
here
. The lowest homework score will be dropped for you.
Unless otherwise indicated, you may talk to other students about the homework problems but each student must hand in their own answers and
write their own code in the programming part. You also must indicate on each homework with whom you collaborated and cite any other sources
you use including Internet sites. Students cannot use old solution sets for this class or solution manual to the textbook under any circumstances.
Homework assignments will be submitted through Gradescope.
Please submit your homework on time. Homework is worth full credit before the due date. It is worth zero credit after the due date.
Exam
There will be one in-class midterm on Oct 31.
Quiz
There will be 6 in-class pop-up quiz for the purpose of reviewing the newly learned concepts. The quizzes are closed book and closed notes. No
electronic aids or cheat sheets are allowed. We will drop the lowest quiz score for you.
Project
Students are required to do a project in this class. The goal of the course project is to provide you an opportunity to either do machine learning
research or solve a real-world problem using machine learning.
The best outcome of the project is a manuscript that is publishable in major machine learning conferences (COLT, ICML, NeurIPS, ICLR,
AISTATS, UAI etc.) or journals (Journal of Machine Learning Research, Machine Learning).
CS260 [Fall2022] Machine Learning Algorithms maintained by 
uclaml
Published with 
GitHub Pages

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
