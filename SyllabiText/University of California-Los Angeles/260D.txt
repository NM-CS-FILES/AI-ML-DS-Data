==================[Syllabus Start]==================
U C L A  
Computer Science Department  
 
Course number : CS260D  
Course Catalog Title : Large Scale Machine Learning  
Short Title : Large Scale Machine Learning  
Units : 4 
Grading basis : Letter Grades  
Format : lecture with discussions  
GE or Major/Minor requirement : No 
Requisites : M146 
Description :   
To alleviate the  costs and improve the robustness and generalization performance of modern 
machine learning models, it becomes crucial to develop methods with strong theoretical guarantees 
to warrant efficient, accurate, and robust learning. The course discusses advan ced topics and state-
of-the-art research to  improve efficiency , robustness, and scalability  of machine learning 
algorithms on large  data. Topics include:  Advanced Optimization, Variance Reduction, 
Distributed Training, Federated Learning, Data Summarization, Robust Learning, Neural Network 
Pruning, Neural Architecture Search, Neural Network Quantization 
 
Justification :  
The great success of modern machine learning systems is contingent on exceptionally large 
computational resources  that enable training complex models on abundant data. This necessitates 
expensive hardware, and incurs a substantial environmental cost due to the significant energy 
consumption. Moreover, as datasets grow, the commonly used data collection, crowd -sourcing , 
and automated data labeling techniques result in noisy labels and malicious data points be ing 
ubiquitous in large real -world datasets. Such examples have a drastic effect on th e performance of 
the trained models. The course discusses various ways to reduce costs of learning from massive 
data and increase robustness of current machine learning methods against noisy and malicious 
examples.  Such a course does not exist at UCLA.  
 
Supplemental Information: --  
 
Grading structure :  
Homework   15% 3 homework assignments  
Class Presentation  25%  
Midterm  30% 8th week of the class (in class; 90 minutes)  
Final Project   30% Presentation and report  
 
Effective Date: Fall 202 2 
 
Syllabus : 
Title: Large scale machine learning                                                        
 
Course Description:  Discussion  of advanced  topics  and state-of-the-art research  to improve  
efficiency  and scalability  of machine  learning  algorithms  to larger  data.  Topics  include  data 
compression, model  (neural  network)  compression, distributed  learning  methods, and improve d 
optimization  methods.  
 
Schedule:    
Part 1   
week 0  Sep 23  Introduction   
week 1  Sep 28  [Adv. opt. ] Momentum &  adaptive lr  (review ), Variance reduction   
Sep 30  [distributed opt.] distributed SGD , Hogwild   
week 2  Oct 5  [distributed opt.] distributed SGD , Hogwild  HW1  
Oct 7  [distributed opt.] federated learning   
week 3  Oct 12  [distributed opt.] federated learning  HW1 due  
Oct 14  [data compression] submodularity   
week 4  Oct 19  [data compression] distributed/streaming algs  HW2  
Oct 21  [data compression] subsets for ML   
week 5  Oct 26  [data compression] robust subsets  HW2 due  
Oct 28  [model compression] NN pruning   
week 6  Nov 2  [model compression] NN pruning  HW3  
Nov 4  [model compression] NAS   
week 7  Nov 9  [model compression] NAS  HW3 due  
Nov 11  Veteran's day  
week 8  Nov 16  Midterm   
Nov 18  [model compression] quantization   
week 9  Nov 23  [model compression] quantization   
Nov 25  Thanksgiving  
week 10  Nov 30  Final project presentations   
Dec 2  Final project presentations   
 
Enrollment and student evaluation numbers from past course offering  
This course was offered as CS 269 in Fall 2021. 24  students took the course with an additional 30-
40 who wanted to take but were unable to due to course capacity. The class went very well and 
most students felt they learned a lot from the course.  
Summary of Reviews (please see the end of this file).  
 
Value - You have learned something you consider valuable.  
Median 9 Average 8.64  
 
Overall -  Your overall rating of the instructor.  
Median 9 Average 8.73  
 
Overall -  Your overall rating of the course.  
Median 9 Average 8.64  
 
 
Students’ Comments (a sample trying to demonstrate both positive and negative comments)  
 
Please identify what you perceive to be the real strengths and weaknesses of this instructor 
and course.  
I really enjoy the class, even though I have a hard time understanding the math part behind the 
theories. The professor used homework assignments to make me understand the math part more 
clearly since she turned the theories into practical problems, which is a lot easier to understand. 
She is also pretty helpful. When you have any questions related to the class materials, she tried her 
best to help you understanding all the concepts.  
I learned a lot and enjoyed this class.  
I thought the course overall was very interesting, especially submodular optimization, NAS, and 
pruning. I would have liked to have some practical coding assignments (nothing super 
complicated) along with the standard homework to get more intuition about some of the concepts.  
Prof. Mirzasoleiman is easily one of the best professors I've had at UCLA. She is extremely 
knowledgeable in large -scale machine learning and is an excellent teacher. She really ensured that 
students were engaged (through real -world examples, jokes, etc.) and reviewed course content 
regularly so everybody felt comfortable with it. Her homework assignments were f antastic and 
really helped me understand the course content better. Her midterm was extremely fair. It was very 
clear that she cared about student success and understanding. It was apparent from the creativity 
and enthusiasm displayed in the final course projects that all the students in the class genuinely 
enjoyed and learned a lot from the class. This class has significantly shaped my research interests. 
I hope, for the benefit of all CS students, that this class becomes a regular offering.  
Professor is incredible! Easily one of the best classes I've taken here at UCLA. I'm surprised that 
the CS department has not made this a permanent class yet, I'm not sure what they are waiting for. 
One of the best professors I've had--she is extremely clear, helpful, and supportive. Could not have 
asked for a better experience.  
Strengths: Relevant practical concepts in ML taught, Prof Baharan is very helpful and is concerned 
about student learning.  Weakness: Slides used in the course were sometimes not very 
informatio nal, Prof went too fast in the beginning of the course in which most concepts were 
mathematical  
Very good course!  

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
