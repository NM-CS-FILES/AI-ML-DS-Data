==================[Syllabus Start]==================
This webpage is for an old version of the
course; content may be out of date!
CSE 255: Dahta Mining and Predictive
Analytics
Winter 2015, Mondays 18:30-21:20, CENTR 222
For the current version of this class, see 
here
CSE 255 is a graduate-level course devoted to current methods for data mining and predictive
analytics. No previous background in machine learning is required, but all participants should be
comfortable with programming (all example code will be in Python), and with basic optimization and
linear algebra.
The course meets once a week on Monday evening, starting January 5. There will be no classes on
January 19 (MLK day) or on February 16 (President's day). Meetings are in CENTR 222.
There is no textbook for the course, though chapter references will be provided from 
Pattern
Recognition and Machine Learning (Bishop)
, and from Charles Elkan's 2013 
course notes
.
Office hours:
 I'll hold office hours on 
Friday 9-11am
 in CSE 4102. Additional office hours will be
held by Dongcai Shen on 
Mondays 10-12
 in CSE 4127. For other discussions see the course's
Piazza page
.
Part 1: Methods
Week
Topics
Files
References
Slides
Homework
1 (Jan
5)
Supervised Learning:
Regression
Least-squares
regression
Overfitting &
regularization
Training, validation,
and testing
50k beer
reviews
lecture1.py
Bishop ch.3
Elkan ch.3,6
introduction
course outline
lecture 1
case study:
reddit
Homework
1
due
January 12
2 (Jan
12)
Supervised Learning:
Classification
Logistic regression
SVMs
Multiclass &
multilabel
classification
How to evaluate
classifiers
50k book
descriptions
5k book cover
images
lecture2.py
homework2.py
Bishop ch.4
Elkan ch.5,8
lecture 2
Homework
2
Homework
3
both due
January 26
3 (Jan
26)
Dimensionality Reduction &
Clustering
Singular value
decomposition &
PCA
K-means &
hierarchical
clustering
Community
detection
facebook ego
network
lecture3.py
Bishop ch.9
Elkan ch.13
lecture 3
assignment 1
case study:
social circes
Homework
4
due
February 2
Assignment
1
due
February
23
reports
Graphical Models &
Interdependent Variables
lecture 4
Homework
4 (Feb
2)
Directed and
undirected models
Labeling via graph-
cuts
Bishop ch.8
case study:
image
labeling
5
due
February 9
Part 2: Applications
Week
Topics
Files
References
Slides
Homework
5 (Feb
9)
Recommender Systems
Latent-factor
models
Collaborative
filtering
homework
6/7 data
assignment
2 data
baselines.py
Elkan ch.11
lecture 5
assignment
2
case study:
beer
experts
Homework 6
Homework 7
both due
February 23
(or morning of
February 25
outside 4102)
Assignment 2
due March 10
6 (Feb
23)
Text Mining
Sentiment analysis
Bags-of-words
TFIDF
Stopwords,
stemming, and
topic models
lecture6.py
Elkan ch.12
lecture 6
case study:
text and
opinions
Homework 8
due March 2
7 (Mar
2)
Network Analysis
Power-laws and
small-worlds
Random graph
models
triads and weak
ties
HITS and
PageRank
Elkan ch.14
Easley &
Kleinberg
lecture 7
case study:
rich-clubs
Homework 9
due March 9
8 (Mar
9)
Modeling Temporal and
Sequence Data
Sliding windows
and autoregression
Hidden Markov
Models
Temporal dynamics
in recommender
systems
Temporal dynamics
in text and social
networks
lecture8.py
lecture 8
no homework!

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
