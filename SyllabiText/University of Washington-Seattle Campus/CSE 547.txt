==================[Syllabus Start]==================
Course Information Spring 2020
CSE 547: Machine Learning for Big Data
Instructor: Tim Altho
Lectures: Tuesday/Thursday 10:00-11:20am PDT via Zoom. You can nd links to the Zoom lectures on
Canvas ( https://canvas.uw.edu/courses/1372006/external_tools/95443 ).
Course website: https://courses.cs.washington.edu/courses/cse547/20sp/
Contact:
Use EdDiscussion to post questions: https://us.edstem.org/courses/422/discussion/ .
For emergencies and personal questions, e-mail us at cse547-instructors@cs.washington.edu
TAs and oce hours: See the course website for times and details.
Topics
MapReduce and Spark/Hadoop
Frequent itemsets and Association rules
Near Neighbor Search in High Dimensions
Locality Sensitive Hashing (LSH)
Dimensionality reduction: SVD and CUR
Recommender Systems
ClusteringAnalysis of massive graphs
Link Analysis: PageRank, HITS
Web spam and TrustRank
Proximity search on graphs
Large-scale supervised machine learning
Mining data streams
Optimizing submodular functions
Assignments and grading
Homeworks (40%): Four problem sets requiring coding and theory (10% each)
Final project (40%)
Colabs (20%): 10 colabs in total, released weekly (2% each)
Extra credit : EdDiscussion and course participation, reporting bugs in course materials (up to 2%)
Homework policy
Questions We try very hard to make questions unambiguous, but some ambiguities may remain. Ask
(i.e., post a question on EdDiscussion) if confused, or state your assumptions explicitly. Reasonable
assumptions will be accepted in case of ambiguous questions.
Honor code We take honor code extremely seriously ( https://www.cs.washington.edu/academics/misconduct ).
We strongly encourage students to form study groups. Students may verbally discuss and work on
homework problems in groups. However, each student must write down the solutions and the code
independently. Students may not share written work or programs (on paper, electronic, or any other
form) with anyone else. Importantly, in submissions, each student should write down the set of people
whom they interacted with including anyone not taking this class or not working at UW (excluding the
instructor and TA(s)). Students should appropriately cite any helpful material they nd in published
literature or on the web including assignment's answer, or partial answer. Students should not claim to
have come up with an idea that wasn't originally theirs; instead, should explain it in their own words
and make it clear where it came from.
Late assignments Each student will have a total of two late periods to use for homeworks. A late period
lasts 48 hours from the original homework deadline. No assignment will be accepted more than one
late period after its due date.
CSE 547: Machine Learning for Big Data, https://courses.cs.washington.edu/courses/cse547/20sp/ 2
Assignment submission All students must submit their homeworks via Gradescope ( http://www.gradescope.
com). Students can typeset or scan their homeworks. Scanned homeworks must be absolutely clear
and legible. Points may be deducted for unclear parts of handwritten homework.
Students also need to upload their code on Gradescope. Put all the code for a single question into a
single le and upload it. Refer to the course FAQ for more info.
Regrade requests We take great care to ensure that grading is fair and consistent. Since we will always
use the same grading procedure, any grades you receive are unlikely to change signicantly. However,
if you feel that your work deserves a regrade, submit your request within a week of receiving your grade
on Gradescope. However, note that we reserve the right to regrade the entire assignment.
Prerequisites
Students are expected to have the following background (recitation sessions will refresh these topics):
The ability to write non-trivial computer programs (at a minimum, at the level of CSE 332, CSE 373,
or equivalent). Good knowledge of Python/Java will be extremely helpful since most assignments will
require the use of Hadoop/Java.
Familiarity with basic probability theory is essential (any introductory probability course).
Familiarity with writing rigorous proofs (e.g. CSE 311 or equivalent).
Familiarity with basic linear algebra (e.g. MATH 308).
Familiarity with algorithmic analysis (e.g. CSE 417, CSE 421).
Materials
Notes and reading assignments will be posted on the course web site. Readings for the class will be from:
Mining Massive Datasets by J. Leskovec, A. Rajaraman, J. Ullman (PDFs at http://mmds.org ).
Important dates
Assignment Out Date Due Date (all 23:59pm)
Colab 0, Colab 1 Apr 2 Apr 9
Assignment 1 Apr 2 Apr 16
Colab 2 Apr 9 Apr 16
Project proposal Apr 23
Colab 3 Apr 16 Apr 23
Assignment 2 Apr 16 Apr 30
Colab 4 Apr 23 Apr 30
Project milestone May 7
Colab 5 Apr 30 May 7
Assignment 3 Apr 30 May 14
Colab 6 May 7 May 14
Colab 7 May 14 May 21
Assignment 4 May 14 May 28
Colab 8 May 21 May 28
Colab 9 May 28 Jun 7
Final report Jun 7
Final presentation Jun 8
CSE 547: Machine Learning for Big Data, https://courses.cs.washington.edu/courses/cse547/20sp/ 3
We will also hold three review sessions in the rst two weeks of the course:
Spark tutorial and help session. Thursday, Apr 2, 1:00-3:00pm.
Review of basic probability and proof techniques. Tuesday, Apr 7, 3:30-5:30pm.
Review of basic linear algebra. Thursday, Apr 9, 1:00-3:00pm.
Next steps for students
Register for EdDiscussion: https://us.edstem.org/courses/422/discussion/
Register for Gradescope: https://www.gradescope.com/courses/95372 with entry code: MP8KGN
Register for Canvas: https://canvas.uw.edu/courses/1372006/
Start planning for the course project. Sign up with your team here: https://forms.gle/oG8ckShER5yDHHs37
Complete Colab 0/1 released on Thursday

===================[Syllabus End]===================
Please examine the attached course syllabus carefully and provide detailed answers to the research questions (RQ) listed below. Each question focuses on specific aspects of "computing systems" tailored for AI/ML scalability. We are looking for specific issues and topics related to compilers, runtime systems, hardware acceleration, code optimization, programming model for AI/ML covered in the syllabus. Programming with Python or jupyter does not count as computing system topics.

RQ 1. Course Content and Frequency:
1.1 How frequently are topics explicitly related to "computing system" specialized for ML/AI discussed in the course? 
The topics are 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in likert scale: 
Frequent (4): At least one dedicated lecture discussed the topics.
Intermittent (3): The topics are discussed occasionally. 
Infrequent (2): The topics are rarely mentioned.
Never mentioned (1): The topics are never mentioned.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 2. Definition and Understanding:
2.1 How are the impacts of "computing systems" on AI/ML explicitly defined and explained in undergraduate curricula? 
The definition and explanation should include concepts of 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Adequate (3): Provide detailed definition and explanation.
Inadequate (2): Many of the topics missed significant discussion in lectures or in assignments.
Undefined (1): The topics are mostly undefined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
2.2 Do courses provide a comprehensive and explicit definition of impacts of "computing systems" on AI/ML?
The definition and explanation should include concepts such as 1) scalable (parallel and distributed) model training, inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer by providing the list of above topics (1 to 9) discussed in the course. Make it short and direct. Limit in 100 words. Do not include topics unrelated to "computing systems" like general ML/AI algorithms.

RQ 3. Requirement Specification:
3.1 How are computational performance and capability requirements for hardware and software systems running scalable AI/ML, explicitly specified and discussed in undergraduate courses?
Topics include 1) Computational Power (CPU, GPU, TPU, Edge AI chips), Memory and Storage, Network for scalable (parallel and distributed) model training, inference; 2) Distributed Computing Frameworks such as TensorFlow's Distributed Strategy, PyTorch's Distributed Data Parallel (DDP), and Horovod 3)  Optimization Techniques such as Efficient Algorithm, Quantization, Prunning 4) Programming Models and Abstractions such as High-Level Libraries (Tensorflow, PyTorch, Keras)
Answer in Likert scale: 
Quantitatively (3): The lectures or assignments provide numerical values for computational performance and capability requirements such as latency, throughput, resource utilization etc.
Qualitatively (2): The lectures used descriptive terms.
No guidelines (1): The Lecture provide no guidelines.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
3.2 How did the discussion of “computing system” requirements rank against the discussion of general AI/ML topics?
Answer in Likert scale: 
Equally discussed with other AI/ML topics (3)
“computing system” requirements is a sub topic (2) 
“computing system” requirements were never discussed (1) 
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 4. Influence and Importance:
4.1 How is the importance of various “computing system” factors of designing and maintaining scalable AI/ML emphasized in the course?
The factors are 1) scalable (parallel and distributed) model training and inference; 2) testing, debugging, and monitoring of ML applications; 3) ML programming models and abstractions; 4) programming languages for machine learning; 5) ML compilers and runtimes; 6) specialized hardware for machine learning; 7) hardware-efficient ML methods; 8) machine learning benchmarks, and tooling.
Answer in Likert scale: 
Holistic (2): The course took into account of many of the above factors.
System (1): The course viewed the factors as low level system issue, relegating responsibility to correct choice of hardware, programming model and AI/ML framework.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.

RQ 5. Case Studies and Real-World Applications:
5.1 Are real-world case studies involving hardware and software systems for AI/ML, with a focus on scalable model training, inference, and serving explicitly included in the curriculum?
Answer in Likert scale: 
Major (2): Computational performance and capability of the underlying system was the major concerns of the case studies.
Minor (1): Computational performance and capability of the underlying system was not a major concern of the case studies.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 6. Awareness and Integration of AI-Specific Engineering Practices:
6.1 Do the courses discuss contributions and best practices from AI/ML system engineering communities, specifically in areas such as compilers, runtime systems, hardware acceleration, and code optimization?
Answer in Likert scale: 
Adequate (3): The courses thoroughly cover contributions from AI/ML system engineering communities and best practices in detail by depicting from state of art.
Inadequate (2): The courses mention the topic but do not cover it in sufficient depth or detail.
Undefined (1): The coverage of this topic in the courses is unclear or not well-defined.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
RQ 7. Projects and Practical Implementation:
7.1 To what extent do the assignments in the course provide hands-on experience with designing, building, and maintaining both scalable hardware and software systems for AI/ML, specifically focusing on compiler optimization, optimizing runtime systems, hardware acceleration, or code optimization for AI/ML?
Answer in Likert scale: 
Adequate (3): The assignments thoroughly cover these areas and provide extensive hands-on experience.
Inadequate (2): The assignments cover these areas minimally and do not provide sufficient hands-on experience.
None (1): The assignments do not cover these areas or provide relevant hands-on experience.
Could not be evaluated (0): Insufficient information or exposure to the assignments on the syllabus to provide an evaluation.
Provide the score based on overall discussion of the above topics. Do not rate each topic individually. No explanation needed.
